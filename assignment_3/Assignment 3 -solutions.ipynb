{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import sys\n",
    "from pprint import pprint\n",
    "from math import log\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np #numpy provides useful maths and vector operations\n",
    "from numpy.random import random_sample\n",
    "import nltk\n",
    "from nltk import FreqDist, ConditionalFreqDist\n",
    "from nltk.tag import *\n",
    "from nltk.corpus import dependency_treebank\n",
    "from nltk.tag.hmm import HiddenMarkovModelTagger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(lcPairs):\n",
    "    '''plot_histogram is a very general function that takes either a dictionary\n",
    "    or a list of label,count pairs (values or counts need to be\n",
    "    numbers), and makes a bar plot showing the count for each label.\n",
    "    '''\n",
    "    plt.clf()\n",
    "    if isinstance(lcPairs, dict):\n",
    "        lcPairs = list(lcPairs.items())\n",
    "    #arange() is like range() but returns a numpy array instead of a list\n",
    "    x_pos = np.arange(len(lcPairs)) \n",
    "    #first arg (x_pos) is the position of left hand side of bar\n",
    "    #second arg (counts) is the height of bar\n",
    "    (labels,counts)=zip(*lcPairs)\n",
    "    plt.bar(x_pos,counts,width=1)\n",
    "    #bar width is 1, so put labels at left side + .5 (middle of bar), rotated slightly\n",
    "    plt.xticks(x_pos+.5, labels, rotation=50)\n",
    "    plt.ylim([0,1.1*max(counts)])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_length_distribution(sents):\n",
    "    ''' tag_distribution takes tagged sentences extracted using nltk libraries\n",
    "    as input and returns a frequency distribution of sentence lengths\n",
    "    '''\n",
    "    fd=defaultdict(int)\n",
    "    for s in sents:\n",
    "        n=len(s)\n",
    "        fd[n]+=1\n",
    "    return fd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_distribution(sents):\n",
    "    ''' tag_distribution takes tagged sentences extracted using nltk libraries\n",
    "    as input and returns a frequency distribution of pos tags\n",
    "    '''\n",
    "    fd=defaultdict(int)\n",
    "    for s in sents:\n",
    "        for (w,t) in s:\n",
    "            fd[t] +=1\n",
    "    return fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tag_distribution(sents):\n",
    "    ''' word_tag_distribution takes tagged sentences extracted using nltk libraries\n",
    "    as input and returns the conditional frequency distribution of word and pos tags\n",
    "    '''\n",
    "    # Instead of using defaultdict, do things a step at a time:\n",
    "    cfd = {}\n",
    "    # For each word,tag tuple in each sentence,\n",
    "    #   create an fd if necessary, and update the tag count\n",
    "    for sent in sents:\n",
    "        for (w,t) in sent:\n",
    "            fd=cfd.setdefault(w,{}) # either get the value,\n",
    "            #print(fd)                        #  or give it an empty dictionary as value\n",
    "            if t in fd:\n",
    "                # a known key\n",
    "                fd[t] +=1\n",
    "            else:\n",
    "                # not previously seen\n",
    "                fd[t] = 1\n",
    "    return cfd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram_tagger(cfd, bpos, sent):\n",
    "    ''' This is a simple pos tagger. It takes conditional frequency \n",
    "    distribution (cfd) of word and its tags, and sentence as input \n",
    "    and assigns pos tags to the words in that sentence. If a word is\n",
    "    seen (present in cfd), it assigns the most frequent tag for that\n",
    "    word. For unseen words (not present in cfd), it assigns a default\n",
    "    pos tag (in this case common noun \"NN\").\n",
    "    '''\n",
    "    words = sent.rstrip().split()\t\n",
    "    ## students need to fill in correct function defn for ut1\n",
    "    ##\n",
    "    ## note that the list comprehension below constructs a list\n",
    "    ## that contains one item for each w in words, where that\n",
    "    ## item is ut1(w,cfd,bpos).\n",
    "    return [ut1(w,cfd,bpos) for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ut1(word,cfd,bpos):\n",
    "    ''' Helper function for unigram_tagger.  Look up the most common tag for\n",
    "        a single word in cfd, using bpos if it's not in there.\n",
    "        Returns a pair (word, tag)'''\n",
    "    if word in cfd:\n",
    "        return  max(cfd[word], key=cfd[word].get)  \n",
    "    else:\n",
    "        return bpos  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence is : The quick brown fox jumped over the lazy dog\n",
      "tags are: ['DT', 'JJ', 'NN', 'NN', 'VBD', 'IN', 'DT', 'NN', 'NN']\n"
     ]
    }
   ],
   "source": [
    "# Extracting tagged sentences using NLTK libraries\n",
    "tsents = dependency_treebank.tagged_sents()\n",
    "if (len(sys.argv)<2 or sys.argv[1]!='-q'):\n",
    "    try:\n",
    "        loaded+=1\n",
    "    except NameError:\n",
    "        loaded=1\n",
    "        print(\"\\nFirst tagged sentence:\\n{}\".format(tsents[0]))\n",
    "        print(\"\\nFirst tuple in the sentence: {}\".format(tsents[0][0]))\n",
    "        print(\"\\nWord in the first tuple: {}\".format(tsents[0][0][0]))\n",
    "        print(\"\\nTag in the first tuple: {}\".format(tsents[0][0][1]))\n",
    "        print(\"\\nTotal Number of sentences: {}\".format(len(tsents)))\n",
    "        print(\"\\nAverage Sentence Length: {}\".format((sum([len(sent) for sent in tsents]))/len(tsents)))\n",
    "        \n",
    "# Sentence length distribution\n",
    "#sent_lengths=sent_length_distribution(tsents)\n",
    "#plot_histogram(sent_lengths) # or plot_histogram(sorted(sent_lengths.items(),key=lambda p:p[0]))\n",
    "\n",
    "# Tag Distribution: uncomment when you've filled in tag_distribution\n",
    "# tag_dist = tag_distribution(tsents)\n",
    "# plot_histogram(sorted(tag_dist.items(),key=lambda p:p[0],reverse=True))\n",
    "\n",
    "# Word Tag Distribution: uncomment when you've filled in word_tag_distribution\n",
    "# word_tag_dist = word_tag_distribution(tsents)\n",
    "# print(\"tags for book are: {}\".format(word_tag_dist[\"book\"]))\n",
    "\n",
    "##UNigram tagger\n",
    "cfd=word_tag_dist\n",
    "bpos=\"NN\"\n",
    "sent='The quick brown fox jumped over the lazy dog'\n",
    "tag_list=unigram_tagger(cfd, bpos, sent)\n",
    "print(\"sentence is : {}\".format(sent))\n",
    "print(\"tags are: {}\".format(tag_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
